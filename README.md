# Internship Scraping and Recommendation System

This repository collects internships from multiple sources, normalizes the data into a single CSV, and exposes a chatbot interface that can search and recommend internships. The chatbot uses a fast local search (rule-based filters / TFâ€‘IDF â€” planned) as the primary method and Gemini (optional) for friendly, explanatory responses.

## Current project state (what this repo actually contains)

- Orchestration: `orchestrator.py` â€” runs scrapers (currently uses main.py), merges results, deduplicates, and writes `data/internships.csv` and a summary file.
- Multi-source scraping: `JobSpy/` (packaged local copy) and an included Internshala scraper in `Internshala-Web-Scraper-Internshala.com/` (these may be present as embedded repos/submodules).
- Chatbot backend: `chatbot/` â€” rule-based `InternshipBot`, CLI (`chatbot/cli.py`), AI wrapper `AIEnhancedInternshipBot` with safe timeouts.
- Data model: `models/internship.py` â€” unified dataclass schema + deduplication helper.
- AI starter: `start_gemini_chatbot.py` â€” loads `.env` automatically (prefer `python-dotenv`) and starts either the AI-enhanced bot or the rule-based bot.
- Data: `data/internships.csv` (generated by orchestrator) and `jobs.csv` (JobSpy output used during orchestration).

## ğŸ“ Simplified project structure

```
placement_portal/
â”œâ”€â”€ Internshala-Web-Scraper-Internshala.com/  # Original internshala script (embedded)
â”œâ”€â”€ chatbot/                             # Chatbot implementation and CLI
â”œâ”€â”€ models/                              # Data models (Internship dataclass)
â”œâ”€â”€ data/                                # Generated CSVs (internships.csv, jobs.csv)
â”œâ”€â”€ orchestrator.py                      # Run scrapers, merge, dedupe, write CSV
â”œâ”€â”€ start_gemini_chatbot.py              # Start AI-enhanced chatbot (auto loads .env)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ›  Installation (quick)

1. Create virtual environment and activate it:

```bash
python3 -m venv venv
source venv/bin/activate
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Put your Gemini key into `.env` (optional):


## ğŸš€ Quick Start â€” run the full flow

1. Run the orchestrator (this will run JobSpy/main.py and produce `data/internships.csv`):

```bash
python orchestrator.py --sources jobspy --max-results 50
```

2. Start the chatbot (will auto-load `.env` for GEMINI_API_KEY):

```bash
python start_gemini_chatbot.py --csv data/internships.csv --ai-timeout 15 --verbose
```

Or use the rule-based CLI:

```bash
python -m chatbot.cli
```

## ğŸ’¬ Usage examples

- `Show me AI/ML internships in Bangalore`
- `List remote internships with Python and machine learning`
- `parse resume path/to/resume.pdf` then `recommend internships based on my profile`

The system will first try a fast, local search (rule-based or TFâ€‘IDF if enabled). Gemini (if configured) is used for nicer explanations and personalization but is optional and configured via `GEMINI_API_KEY`.

## ğŸ”§ Notes & troubleshooting

- If `data/internships.csv` is empty:

  - Run `python orchestrator.py --sources jobspy --max-results 50` and inspect `jobs.csv` created by JobSpy.
  - Some sources may block requests or require JS rendering â€” consider enabling Playwright for those sources.

- Rate limiting: You may see HTTP 429 from some providers (ZipRecruiter etc.). The orchestrator will still proceed with other sources. Use delays, rotate proxies, or reduce `results_wanted`.

- AI timeouts: AI calls are limited (default 10s) and configurable with `--ai-timeout`. If Gemini is slow or unavailable the bot falls back to local results.

## âœ… Recommended next improvements

1. Add a TFâ€‘IDF or BM25 local index for fast, high-quality candidate retrieval (planned; I can implement this). This will make the chatbot respond sub-second for most queries and drastically reduce reliance on Gemini for basic retrieval.
2. Convert interactive scrapers into reusable modules and add Playwright for JS-heavy sites.
3. Normalize stipend and date fields during orchestration.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Add your scraper or improvements
4. Test locally (run `orchestrator.py --dry-run` and verify `data/internships.csv`)
5. Submit a pull request

---

If you want, I can implement the TFâ€‘IDF search + caching next and wire it into the chatbot so queries return instantly â€” say the word and I'll make the change and run a demo.
